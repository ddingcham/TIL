# es에서 검색으로 조회될(안될)데이터 관리  

## [RDB부터 검색엔진까지 ... 내게 꼭 맞는 DB 고르기](http://www.ciokorea.com/news/38041)  
```
일래스틱서치는 비관계형 문서 기반 데이터 저장 및 검색 솔루션이다.
-> 데이터의 저장과 고속 검색에 맞게 배열되고 최적화돼 있다.

강점 : 뛰어난 확장성 -> 유연한 스키마와 기록의 빠른 검색
      -> 전문 검색, 추천, 복잡한 검색 표현 등 지원  
      
약점 : 기본 데이터베이스로 사용하기 보다는 중간 또는 보완 저장소로 더 많이 사용
      -> 고유의 인증 또는 접근 통제 기능이 없음  
      -> 트랜잭션 미지원  
      
적합한 경우 : 검색에 대한 빠른 처리, 로깅 등  
```

## 필요해진 데이터와 필요 없어진 데이터의 관리  
### [시스템 엔지니어의 ES 삽질기](https://brunch.co.kr/@alden/34)  
#### Hot - Warm 아키텍처  
#### // 아이디어의 모티브가 됨  
**Hot한 데이터**를 담당하는 노드와 **Warm한 데이터**를 담당하는 노드로 분리  
  > 수십 TB의 저장공간이 필요한 클러스터라도 최근 데이터 수 TB 정도만 SSD에 담아두고,  
  > 나머지는 상대적으로 저렴하고 많은 데이터를 넣을 수 있는 SATA 쪽으로  

* <다시 내껄 해결한다면?>
  * 상황  
    * Hot : 현재 검색 조건에 의해 조회될 데이터  
    * Warm : 현재 검색 조건에 의해 조회되지 않을 데이터  
    * 검색 조건 : 예를 들어 시간에 의존하는 조건  
      // 지나간 시간에 대해서는 검색에 의해 조회 될 일이 없음  
    * 그치만 위에서 처럼, 노드/클러스터 레벨에서 관리할 규모는 아닌 거 같음  

  * 목표  
    > Hot한 데이터만 es 클러스터에 인덱싱 되어 있고,  
    > Warm한 데이터는 따로 보관하는 상황을 조성하기  
      >> (도큐먼트를 json으로 정의한 형태의 데이터가 꼭 es로 관리될 필요가 없음)  
      >> 빠르게 재구축할 수 있도록 세팅된 상황만 조성하면 됨  
  
  * 방식 스케치  
    > 그러려면 데이터 관리의 편의를 위해  
    > 인덱스 레벨에서의 설계 시 데이터의 특성 중 시간이라는 조건을 반영해서 설계하면 좋을 것 같음  
    
    * es 인덱스 내부에서는 데이터를 실제로 수정/삭제 하지 않는다.  
      * (수정 자체가 기존 문서는 남아있고 새로 문서가 업데이트되면, 문서 내부를 버젼으로 분류하는 개념.)  
      * (삭제도 마찮가지 기존 문서는 남아있고, 문서나 문서 내부를 삭제하면, 비어있는 버젼으로 바뀌는 개념.)  
      
  * 비슷한 사례 발견  
    #### // 비슷한 방법으로 해결한 사례가 있었음  
    > https://www.ridicorp.com/blog/2018/11/20/index-aliases/  
      * 내부 원리  
        ```
        그러면 지워진 데이터는 영원히 남아있는 걸까요? 그렇지 않습니다. 
        지웠다는 표시를 단 채 디스크에 남아 있다가 백그라운드로 주기적으로 또는 특정 임계치를 넘기면 
        더 이상 필요없어진 데이터들을 정리하고 새로운 세그먼트에 병합한 후 기존 세그먼트를 삭제합니다. 
        이때 비로소 디스크에서 완전히 삭제되는데 이를 세그먼트 병합(Segment Merging)이라고 합니다.
        
        세그먼트 병합은 In-Place 업데이트가 아닙니다. 
        새로운 세그먼트를 만들 공간이 있어야 하기 때문에 디스크가 이미 꽉 찬 상태에서는 무용지물입니다. 
        따라서 디스크가 가득찬 상태에서는 세그먼트 병합을 기반으로 하는 삭제 방법은 사용할 수 없습니다.
        ```  
        
      * 솔루션 예시  
        ```
        대안을 찾다가 색인을 삭제하면 그 즉시 디스크에서 삭제된다는 사실이 떠올랐습니다. 
        게다가 _delete_by_query API 를 사용하여 문서를 삭제하는 방법보다 효율적입니다. 
        하지만 기존에는 하나의 색인에 모든 로그 데이터를 저장하고 있었기 때문에 그 하나의 색인을 무작정 삭제할 수는 없었습니다. 
        고민 끝에 기존 색인을 포기하고 새로운 색인을 만들어 Log Rotation을 적용해 보기로 했습니다.

        Log Rotation 방법은 다음과 같습니다. 
        일 단위로 예를 들었지만, 운영하시는 로그 시스템 규모에 따라 시간 단위, 주 단위, 월 단위 등등 얼마든지 자유롭게 구성하셔도 됩니다.

        일 단위로 새로운 색인을 만듭니다. (색인명에 날짜정보를 넣으면 구분하기 좋습니다.)
        로그 데이터는 오늘 생성한 색인에 저장합니다.
        가장 오래된 (N일 전에 생성한) 색인을 삭제합니다.
        로그 분석시에는 최근 N일 간의 모든 색인에서 조회합니다.
        ```
        
#### 결론 : **적합한 "어떻게"**의 기준은 **"왜(요구사항)"**에 힌트가 있음  
      
      
